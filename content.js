// YouTube Transcript Extractor - Content Script
console.log("YouTube Transcript Extractor loaded");

class YouTubeTranscriptExtractor {
  constructor() {
    this.currentVideoId = null;
    this.captionTracks = [];
    this.setupMessageListener();
    this.injectTranscriptCapture();
    this.setupTranscriptListener();
  }

  setupMessageListener() {
    chrome.runtime.onMessage.addListener((request, sender, sendResponse) => {
      if (request.action === "getVideoInfo") {
        this.handleGetVideoInfo(sendResponse);
        return true; // Will respond asynchronously
      } else if (request.action === "fetchTranscript") {
        this.handleFetchTranscript(request.captionTrack, sendResponse);
        return true; // Will respond asynchronously
      }
    });
  }

  // Inject script into page context to run before YouTube's scripts
  injectTranscriptCapture() {
    console.log("ðŸš€ Injecting transcript capture script...");

    const script = document.createElement("script");
    script.src = chrome.runtime.getURL("inject.js");

    // Inject into head as early as possible
    (document.head || document.documentElement).appendChild(script);

    console.log("âœ… Transcript capture script injected");
  }

  // Listen for transcript capture events from injected script
  setupTranscriptListener() {
    document.addEventListener("youtubeTranscriptCaptured", (event) => {
      console.log("ðŸ“¡ Received transcript capture event:", event.detail);
      console.log("ðŸ“¡ Event fired on URL:", window.location.href);
      console.log("ðŸ“¡ Event fired on pathname:", window.location.pathname);
      console.log("ðŸ“¡ Current video ID check:", this.getVideoId());
      this.handleCapturedTranscript(event.detail);
    });
  }

  // Process captured transcript from injected script
  async handleCapturedTranscript(captureData) {
    try {
      const { url, response } = captureData;

      console.log("ðŸ” Processing captured transcript:", url);
      console.log("ðŸ” Current page URL:", window.location.href);
      console.log("ðŸ” Current page pathname:", window.location.pathname);

      if (!response || response.trim() === "") {
        console.log("âŒ Empty response received");
        return;
      }

      // Try to parse as JSON first (YouTube's new format), fallback to XML
      let parsedTranscript;
      try {
        const jsonData = JSON.parse(response);
        parsedTranscript = this.parseTranscriptJSON(jsonData);
      } catch (jsonError) {
        // Fallback to XML parsing (mirror fetchTranscript logic)
        console.log("JSON parsing failed, trying XML:", jsonError);
        parsedTranscript = this.parseTranscriptXML(response);
      }

      if (parsedTranscript.length > 0) {
        console.log(
          "âœ… Successfully parsed transcript with",
          parsedTranscript.length,
          "segments"
        );

        // Format transcript
        const formattedTranscript = this.formatTranscript(
          parsedTranscript,
          false
        );
        const timestampedTranscript = this.formatTranscript(
          parsedTranscript,
          true
        );

        // Determine language and type from URL
        const urlObj = new URL(url);
        const lang = urlObj.searchParams.get("lang") || "en";
        const isAutoGenerated = urlObj.searchParams.get("kind") === "asr";

        // Get current video ID for storage
        const currentVideoId = this.getVideoId();
        if (!currentVideoId) {
          console.error("âŒ No video ID found for captured transcript");
          return;
        }

        // Send to background service worker with video ID (with retry for context invalidation)
        const sendTranscriptToBackground = async (attempt = 1) => {
          try {
            chrome.runtime.sendMessage(
              {
                action: "transcriptCaptured",
                videoId: currentVideoId,
                data: {
                  transcript: formattedTranscript,
                  timestampedTranscript: timestampedTranscript,
                  segments: parsedTranscript,
                  language: lang,
                  isAutoGenerated: isAutoGenerated,
                  wordCount: formattedTranscript.split(" ").length,
                  captureMethod: "Auto-capture (Injected Script)",
                },
              },
              (response) => {
                if (chrome.runtime.lastError) {
                  if (
                    chrome.runtime.lastError.message.includes(
                      "context invalidated"
                    ) &&
                    attempt === 1
                  ) {
                    console.warn(
                      "ðŸ”„ Extension context invalidated, retrying in 1 second..."
                    );
                    setTimeout(() => sendTranscriptToBackground(2), 1000);
                    return;
                  }
                  console.warn(
                    "Background script not available:",
                    chrome.runtime.lastError.message
                  );
                  return;
                }
                console.log("âœ… Transcript sent to background successfully");
              }
            );
          } catch (error) {
            if (
              error.message.includes("Extension context invalidated") &&
              attempt === 1
            ) {
              console.warn(
                "ðŸ”„ Extension context invalidated, retrying in 1 second..."
              );
              setTimeout(() => sendTranscriptToBackground(2), 1000);
            } else {
              console.error(
                "âŒ Failed to send transcript to background:",
                error
              );
            }
          }
        };

        await sendTranscriptToBackground();
      } else {
        console.log("âŒ No transcript segments found in response");
      }
    } catch (error) {
      console.error("âŒ Error processing captured transcript:", error);
    }
  }

  // Extract video ID from current YouTube URL
  getVideoId() {
    // Add diagnostic logging
    console.log("ðŸ” getVideoId() called - URL:", window.location.href);
    console.log("ðŸ” pathname:", window.location.pathname);
    console.log("ðŸ” search params:", window.location.search);

    const urlParams = new URLSearchParams(window.location.search);
    const videoId = urlParams.get("v");

    console.log("ðŸ” extracted videoId:", videoId);

    if (!videoId && window.location.pathname.startsWith("/watch")) {
      // Fallback for edge cases
      console.log("ðŸ” No videoId but on /watch path - returning null");
      return null;
    }

    // Check if we're on a non-video page
    if (!videoId) {
      console.log(
        "ðŸ” No videoId found - likely on non-video page (homepage, search, etc.)"
      );
    }

    return videoId;
  }

  // Get video title from page
  getVideoTitle() {
    // Try multiple selectors as YouTube's DOM can vary
    const selectors = [
      "h1.ytd-watch-metadata #title",
      "h1.title yt-formatted-string",
      ".watch-main-col .watch-title",
      'h1[class*="title"]',
    ];

    for (const selector of selectors) {
      const titleElement = document.querySelector(selector);
      if (titleElement && titleElement.textContent.trim()) {
        return titleElement.textContent.trim();
      }
    }

    return "YouTube Video";
  }

  // Extract caption tracks from ytInitialPlayerResponse
  getCaptionTracks() {
    try {
      // First try to get from window objects
      let playerResponse = null;

      if (window.ytInitialPlayerResponse) {
        playerResponse = window.ytInitialPlayerResponse;
      } else {
        // Try to extract from script tags
        const scripts = document.querySelectorAll("script");
        for (const script of scripts) {
          const content = script.textContent;
          if (content && content.includes("ytInitialPlayerResponse")) {
            const match = content.match(
              /ytInitialPlayerResponse\s*[=:]\s*({.+?});/
            );
            if (match) {
              playerResponse = JSON.parse(match[1]);
              break;
            }
          }
        }
      }

      if (!playerResponse || !playerResponse.captions) {
        return [];
      }

      // cSpell:ignore Tracklist
      const captionRenderer =
        playerResponse.captions.playerCaptionsTracklistRenderer;
      if (!captionRenderer || !captionRenderer.captionTracks) {
        return [];
      }

      return captionRenderer.captionTracks.map((track) => ({
        baseUrl: track.baseUrl,
        languageCode: track.languageCode,
        name: track.name?.simpleText || track.languageCode,
        kind: track.kind || "manual", // 'asr' for auto-generated, undefined/manual for uploaded
        isAutoGenerated: track.kind === "asr",
      }));
    } catch (error) {
      console.error("Error extracting caption tracks:", error);
      return [];
    }
  }

  // Handle request for video information and attempt automatic transcript extraction
  async handleGetVideoInfo(sendResponse) {
    try {
      const videoId = this.getVideoId();
      if (!videoId) {
        sendResponse({
          success: false,
          error:
            "No video ID found. Please make sure you are on a YouTube video page.",
        });
        return;
      }

      const title = this.getVideoTitle();
      const captionTracks = this.getCaptionTracks();

      this.currentVideoId = videoId;
      this.captionTracks = captionTracks;

      // If no caption tracks, return immediately with guidance to use auto-capture
      if (!captionTracks.length) {
        sendResponse({
          success: true,
          data: {
            videoId,
            title,
            captionTracks: [],
            hasTranscripts: false,
            manualExtractionFailed: false,
            noTracksFound: true,
          },
        });
        return;
      }

      // Automatically attempt transcript extraction with the first available track
      console.log("ðŸ” Automatically checking manual transcript extraction...");
      try {
        const firstTrack = captionTracks[0];
        const extractionResult = await this.attemptTranscriptExtraction(
          firstTrack
        );

        if (extractionResult.success) {
          console.log("âœ… Manual transcript extraction successful");
          sendResponse({
            success: true,
            data: {
              videoId,
              title,
              captionTracks,
              hasTranscripts: true,
              manualExtractionFailed: false,
              extractedTranscript: extractionResult.data,
            },
          });
        } else {
          console.log(
            "âŒ Manual transcript extraction failed, will guide to auto-capture"
          );
          sendResponse({
            success: true,
            data: {
              videoId,
              title,
              captionTracks,
              hasTranscripts: false,
              manualExtractionFailed: true,
              extractionError: extractionResult.error,
            },
          });
        }
      } catch (extractionError) {
        console.log(
          "âŒ Manual transcript extraction failed, will guide to auto-capture"
        );
        sendResponse({
          success: true,
          data: {
            videoId,
            title,
            captionTracks,
            hasTranscripts: false,
            manualExtractionFailed: true,
            extractionError: extractionError.message,
          },
        });
      }
    } catch (error) {
      console.error("Error getting video info:", error);
      sendResponse({
        success: false,
        error: "Failed to extract video information: " + error.message,
      });
    }
  }

  // Attempt to extract transcript from a caption track
  async attemptTranscriptExtraction(captionTrack) {
    try {
      if (!captionTrack || !captionTrack.baseUrl) {
        throw new Error("Invalid caption track provided");
      }

      // Use the original baseUrl with minimal modifications
      const urlObj = new URL(captionTrack.baseUrl);
      if (!urlObj.searchParams.has("fmt")) {
        urlObj.searchParams.set("fmt", "json3");
      }

      const transcriptUrl = urlObj.toString();
      console.log("Testing transcript extraction from:", transcriptUrl);

      const response = await fetch(transcriptUrl);
      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }

      const responseText = await response.text();

      // Try to parse as JSON first (YouTube's new format)
      let parsedTranscript;
      try {
        const jsonData = JSON.parse(responseText);
        parsedTranscript = this.parseTranscriptJSON(jsonData);
      } catch (jsonError) {
        // Fallback to XML parsing
        console.log("JSON parsing failed, trying XML:", jsonError);
        parsedTranscript = this.parseTranscriptXML(responseText);
      }

      if (parsedTranscript.length === 0) {
        throw new Error("No transcript segments found");
      }

      const formattedTranscript = this.formatTranscript(
        parsedTranscript,
        false
      );
      const timestampedTranscript = this.formatTranscript(
        parsedTranscript,
        true
      );

      return {
        success: true,
        data: {
          transcript: formattedTranscript,
          timestampedTranscript: timestampedTranscript,
          segments: parsedTranscript,
          language: captionTrack.name,
          isAutoGenerated: captionTrack.isAutoGenerated,
          wordCount: formattedTranscript.split(" ").length,
        },
      };
    } catch (error) {
      return {
        success: false,
        error: error.message,
      };
    }
  }

  // Parse JSON transcript response (YouTube's newer format)
  parseTranscriptJSON(jsonData) {
    try {
      const transcript = [];

      // YouTube's JSON3 format has events array
      if (jsonData.events) {
        jsonData.events.forEach((event) => {
          // cSpell:ignore segs
          if (event.segs) {
            // Each event has segments (segs) with text
            const eventStart = event.tStartMs / 1000; // Convert from milliseconds
            const eventDuration = (event.dDurationMs || 0) / 1000;

            let eventText = "";
            event.segs.forEach((seg) => {
              if (seg.utf8) {
                eventText += seg.utf8;
              }
            });

            if (eventText.trim()) {
              transcript.push({
                text: this.decodeHTMLEntities(eventText.trim()),
                start: eventStart,
                duration: eventDuration,
                end: eventStart + eventDuration,
              });
            }
          }
        });
      }

      return transcript;
    } catch (error) {
      console.error("Error parsing transcript JSON:", error);
      throw new Error("Failed to parse transcript JSON");
    }
  }

  // Parse XML transcript response (fallback for older format)
  parseTranscriptXML(xmlString) {
    try {
      const parser = new DOMParser();
      const xmlDoc = parser.parseFromString(xmlString, "text/xml");
      const textElements = xmlDoc.querySelectorAll("text");

      const transcript = [];
      textElements.forEach((element) => {
        const text = element.textContent.trim();
        const start = parseFloat(element.getAttribute("start") || "0");
        const duration = parseFloat(element.getAttribute("dur") || "0");

        if (text) {
          transcript.push({
            text: this.decodeHTMLEntities(text),
            start: start,
            duration: duration,
            end: start + duration,
          });
        }
      });

      return transcript;
    } catch (error) {
      console.error("Error parsing transcript XML:", error);
      throw new Error("Failed to parse transcript XML");
    }
  }

  // Decode HTML entities in transcript text
  decodeHTMLEntities(text) {
    const textarea = document.createElement("textarea");
    textarea.innerHTML = text;
    return textarea.value;
  }

  // Format transcript for display
  formatTranscript(transcript, includeTimestamps = false) {
    if (includeTimestamps) {
      return transcript
        .map((segment) => {
          const minutes = Math.floor(segment.start / 60);
          const seconds = Math.floor(segment.start % 60);
          const timestamp = `${minutes}:${seconds.toString().padStart(2, "0")}`;
          return `[${timestamp}] ${segment.text}`;
        })
        .join("\n");
    } else {
      return transcript.map((segment) => segment.text).join(" ");
    }
  }

  // Handle request to fetch transcript
  async handleFetchTranscript(captionTrack, sendResponse) {
    try {
      if (!captionTrack || !captionTrack.baseUrl) {
        throw new Error("Invalid caption track provided");
      }

      // Use the original baseUrl with minimal modifications
      // Keep existing auth parameters, only ensure JSON format
      const urlObj = new URL(captionTrack.baseUrl);
      if (!urlObj.searchParams.has("fmt")) {
        urlObj.searchParams.set("fmt", "json3");
      }

      const transcriptUrl = urlObj.toString();
      console.log("Fetching transcript from:", transcriptUrl);

      const response = await fetch(transcriptUrl);
      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }

      const responseText = await response.text();
      console.log(
        "Response content (first 200 chars):",
        responseText.substring(0, 200)
      );

      // Try to parse as JSON first (YouTube's new format)
      let parsedTranscript;
      try {
        const jsonData = JSON.parse(responseText);
        parsedTranscript = this.parseTranscriptJSON(jsonData);
      } catch (jsonError) {
        // Fallback to XML parsing
        console.log("JSON parsing failed, trying XML:", jsonError);
        parsedTranscript = this.parseTranscriptXML(responseText);
      }

      if (parsedTranscript.length === 0) {
        throw new Error(
          "Transcript not available. Try turning on closed captions (CC) on the video player and use auto-capture instead."
        );
      }

      const formattedTranscript = this.formatTranscript(
        parsedTranscript,
        false
      );
      const timestampedTranscript = this.formatTranscript(
        parsedTranscript,
        true
      );

      sendResponse({
        success: true,
        data: {
          transcript: formattedTranscript,
          timestampedTranscript: timestampedTranscript,
          segments: parsedTranscript,
          language: captionTrack.name,
          isAutoGenerated: captionTrack.isAutoGenerated,
          wordCount: formattedTranscript.split(" ").length,
        },
      });
    } catch (error) {
      console.error("Error fetching transcript:", error);
      sendResponse({
        success: false,
        error: "Failed to fetch transcript: " + error.message,
      });
    }
  }
}

// Initialize the extractor when the script loads
const transcriptExtractor = new YouTubeTranscriptExtractor();

// Listen for navigation changes using History API (more efficient than MutationObserver)
let lastUrl = location.href;

// Hook into History API for SPA navigation detection
const originalPushState = history.pushState;
const originalReplaceState = history.replaceState;

history.pushState = function (...args) {
  originalPushState.apply(history, args);
  checkUrlChange();
};

history.replaceState = function (...args) {
  originalReplaceState.apply(history, args);
  checkUrlChange();
};

// Also listen for popstate events
window.addEventListener("popstate", checkUrlChange);

function checkUrlChange() {
  const currentUrl = location.href;
  if (currentUrl !== lastUrl) {
    lastUrl = currentUrl;

    // Get the new video ID
    const newVideoId = transcriptExtractor.getVideoId();

    // Clear previous video transcripts if we have a current video ID
    if (newVideoId && newVideoId !== transcriptExtractor.currentVideoId) {
      console.log(
        `ðŸ—‘ï¸ Navigation detected: ${transcriptExtractor.currentVideoId} â†’ ${newVideoId}`
      );

      // Tell background to clear previous video transcripts and update badge
      try {
        chrome.runtime.sendMessage(
          {
            action: "clearPreviousVideoTranscripts",
            currentVideoId: newVideoId,
          },
          (response) => {
            if (chrome.runtime.lastError) {
              console.log(
                "Background script not available for cleanup:",
                chrome.runtime.lastError.message
              );
            }
          }
        );
      } catch (error) {
        if (error.message.includes("Extension context invalidated")) {
          console.log(
            "ðŸ”„ Extension context invalidated during navigation cleanup"
          );
        } else {
          console.log("Background script not ready:", error);
        }
      }
    }

    // Reset state when navigating to a new video
    transcriptExtractor.currentVideoId = newVideoId;
    transcriptExtractor.captionTracks = [];
    console.log("YouTube navigation detected, state reset");
  }
}
